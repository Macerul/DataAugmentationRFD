{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222a383-4659-42e8-9754-7cbd9e8f17f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "# Parametri principali\n",
    "LABEL_COLUMN = \"class\"\n",
    "MODEL_NAME = \"llama3\"     # Cambia con il modello Ollama che preferisci\n",
    "N_FEW_SHOT = 5             # Numero di esempi da passare al modello\n",
    "N_GEN_AT_TIME = 10             # Numero di esempi da generare\n",
    "\n",
    "def call_ollama(prompt: str, model: str = MODEL_NAME) -> str:\n",
    "    \"\"\"\n",
    "    Interroga Ollama in locale e restituisce la risposta testuale.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", model],\n",
    "            input=prompt.encode(\"utf-8\"),\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            check=True\n",
    "        )\n",
    "        return result.stdout.decode(\"utf-8\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"‚ùå Errore nell'interrogazione di Ollama:\", e.stderr.decode(\"utf-8\"))\n",
    "        return \"\"\n",
    "\n",
    "def generate_with_llm(file, minority_examples: pd.DataFrame, n_generate: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Chiede all'LLM di generare nuove tuple coerenti con la classe minoritaria.\n",
    "    \"\"\"\n",
    "    # Converti i few-shot in testo leggibile\n",
    "    examples_text = minority_examples.to_csv(index=False, sep=\";\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Sei un assistente che genera nuovi esempi per bilanciare un dataset.\n",
    "        Ti verranno fornite alcune tuple di riferimento (few-shot) appartenenti alla stessa classe.\n",
    "        Genera {N_GEN_AT_TIME} nuove tuple realistiche e coerenti con la distribuzione dei dati.\n",
    "        Restituisci SOLO un output CSV valido con lo stesso schema (stesse colonne, separatore \",m\").\n",
    "        \n",
    "        Esempi (classe minoritaria):\n",
    "        {examples_text}\n",
    "        Output CSV:\n",
    "        \"\"\"\n",
    "    response = call_ollama(prompt)\n",
    "    #print(response)\n",
    "    with open(\"./LLM/{}_{}_{}_{}.txt\".format(file.replace(\".csv\",\"\"),MODEL_NAME, n_generate, n_generate+N_GEN_AT_TIME), \"w\") as text_file:\n",
    "        text_file.write(\"%s\" % response)\n",
    "    '''  \n",
    "    try:\n",
    "        # Leggi la risposta come CSV\n",
    "        df_new = pd.read_csv(pd.compat.StringIO(response), sep=\";\")\n",
    "        return df_new\n",
    "    except Exception:\n",
    "        print(\"‚ö†Ô∏è Non √® stato possibile leggere la risposta come CSV, restituisco vuoto.\")\n",
    "        return pd.DataFrame()\n",
    "    '''  \n",
    "\n",
    "def augment_dataset(file):\n",
    "    print(f\"\\nüìÇ Analizzando dataset: {file}\")\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    if LABEL_COLUMN not in df.columns:\n",
    "        print(f\"  ‚ùå Colonna '{LABEL_COLUMN}' non trovata in {file}.\")\n",
    "        return\n",
    "\n",
    "    # Conta le classi\n",
    "    counts = df[LABEL_COLUMN].value_counts()\n",
    "    majority_class = counts.idxmax()\n",
    "    minority_class = counts.idxmin()\n",
    "\n",
    "    print(f\"  üîπ Classe maggioritaria: {majority_class} ({counts[majority_class]})\")\n",
    "    print(f\"  üîπ Classe minoritaria: {minority_class} ({counts[minority_class]})\")\n",
    "\n",
    "    # Numero di nuove tuple da generare\n",
    "    diff = counts[majority_class] - counts[minority_class]\n",
    "    if diff <= 0:\n",
    "        print(\"  ‚úÖ Dataset gi√† bilanciato. Nessuna generazione necessaria.\")\n",
    "        return\n",
    "\n",
    "    print(f\"  ‚ûï Generer√≤ {diff} nuove tuple per bilanciare la classe minoritaria.\")\n",
    "\n",
    "    # Preleva 5 esempi della classe minoritaria per il few-shot\n",
    "    few_shot = df[df[LABEL_COLUMN] == minority_class].sample(\n",
    "        min(N_FEW_SHOT, counts[minority_class]), random_state=42\n",
    "    )\n",
    "\n",
    "    # Genera nuove tuple con Ollama\n",
    "    for i in range(0,diff+10,N_GEN_AT_TIME):\n",
    "        print(\"\\t Genero da {} a {}\".format(i, i+N_GEN_AT_TIME))\n",
    "        new_data = generate_with_llm(file, few_shot, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b286659-0195-47b6-a2ac-a6389e97bffd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris0.csv\n",
      "newthyroid2.csv\n",
      "Migraine_onevsrest_4.csv\n",
      "Migraine_onevsrest_5.csv\n",
      "Migraine_onevsrest_1.csv\n",
      "abalone19.csv\n",
      "Migraine_onevsrest_0.csv\n",
      "Migraine_onevsrest_2.csv\n",
      "Migraine_onevsrest_3.csv\n",
      "transfusion.csv\n",
      "new-thyroid1.csv\n",
      "kddcup-guess_passwd_vs_satan.csv\n",
      "ecoli1.csv\n",
      "cleveland-0_vs_4.csv\n",
      "ecoli-0_vs_1.csv\n",
      "Obesity_onevsrest_0.csv\n",
      "Obesity_onevsrest_1.csv\n",
      "\n",
      "üìÇ Analizzando dataset: Obesity_onevsrest_1.csv\n",
      "  üîπ Classe maggioritaria: 0 (1805)\n",
      "  üîπ Classe minoritaria: 1 (282)\n",
      "  ‚ûï Generer√≤ 1523 nuove tuple per bilanciare la classe minoritaria.\n",
      "\t Genero da 0 a 10\n",
      "\t Genero da 10 a 20\n",
      "\t Genero da 20 a 30\n",
      "\t Genero da 30 a 40\n",
      "\t Genero da 40 a 50\n",
      "\t Genero da 50 a 60\n",
      "\t Genero da 60 a 70\n",
      "\t Genero da 70 a 80\n",
      "\t Genero da 80 a 90\n",
      "\t Genero da 90 a 100\n",
      "\t Genero da 100 a 110\n",
      "\t Genero da 110 a 120\n",
      "\t Genero da 120 a 130\n",
      "\t Genero da 130 a 140\n",
      "\t Genero da 140 a 150\n",
      "\t Genero da 150 a 160\n",
      "\t Genero da 160 a 170\n",
      "\t Genero da 170 a 180\n",
      "\t Genero da 180 a 190\n",
      "\t Genero da 190 a 200\n",
      "\t Genero da 200 a 210\n",
      "\t Genero da 210 a 220\n",
      "\t Genero da 220 a 230\n",
      "\t Genero da 230 a 240\n",
      "\t Genero da 240 a 250\n",
      "\t Genero da 250 a 260\n",
      "\t Genero da 260 a 270\n",
      "\t Genero da 270 a 280\n",
      "\t Genero da 280 a 290\n",
      "\t Genero da 290 a 300\n",
      "\t Genero da 300 a 310\n",
      "\t Genero da 310 a 320\n",
      "\t Genero da 320 a 330\n",
      "\t Genero da 330 a 340\n",
      "\t Genero da 340 a 350\n",
      "\t Genero da 350 a 360\n",
      "\t Genero da 360 a 370\n",
      "\t Genero da 370 a 380\n",
      "\t Genero da 380 a 390\n",
      "\t Genero da 390 a 400\n",
      "\t Genero da 400 a 410\n",
      "\t Genero da 410 a 420\n",
      "\t Genero da 420 a 430\n",
      "\t Genero da 430 a 440\n",
      "\t Genero da 440 a 450\n",
      "\t Genero da 450 a 460\n",
      "\t Genero da 460 a 470\n",
      "\t Genero da 470 a 480\n",
      "\t Genero da 480 a 490\n",
      "\t Genero da 490 a 500\n",
      "\t Genero da 500 a 510\n",
      "\t Genero da 510 a 520\n",
      "\t Genero da 520 a 530\n",
      "\t Genero da 530 a 540\n",
      "\t Genero da 540 a 550\n",
      "\t Genero da 550 a 560\n",
      "\t Genero da 560 a 570\n",
      "\t Genero da 570 a 580\n",
      "\t Genero da 580 a 590\n",
      "\t Genero da 590 a 600\n",
      "\t Genero da 600 a 610\n",
      "\t Genero da 610 a 620\n",
      "\t Genero da 620 a 630\n",
      "\t Genero da 630 a 640\n",
      "\t Genero da 640 a 650\n",
      "\t Genero da 650 a 660\n",
      "\t Genero da 660 a 670\n",
      "\t Genero da 670 a 680\n",
      "\t Genero da 680 a 690\n",
      "\t Genero da 690 a 700\n",
      "\t Genero da 700 a 710\n",
      "\t Genero da 710 a 720\n",
      "\t Genero da 720 a 730\n",
      "\t Genero da 730 a 740\n",
      "\t Genero da 740 a 750\n",
      "\t Genero da 750 a 760\n",
      "\t Genero da 760 a 770\n",
      "\t Genero da 770 a 780\n",
      "\t Genero da 780 a 790\n",
      "\t Genero da 790 a 800\n",
      "\t Genero da 800 a 810\n",
      "\t Genero da 810 a 820\n",
      "\t Genero da 820 a 830\n",
      "\t Genero da 830 a 840\n",
      "\t Genero da 840 a 850\n",
      "\t Genero da 850 a 860\n",
      "\t Genero da 860 a 870\n",
      "\t Genero da 870 a 880\n",
      "\t Genero da 880 a 890\n",
      "\t Genero da 890 a 900\n",
      "\t Genero da 900 a 910\n",
      "\t Genero da 910 a 920\n",
      "\t Genero da 920 a 930\n",
      "\t Genero da 930 a 940\n",
      "\t Genero da 940 a 950\n",
      "\t Genero da 950 a 960\n",
      "\t Genero da 960 a 970\n",
      "\t Genero da 970 a 980\n",
      "\t Genero da 980 a 990\n",
      "\t Genero da 990 a 1000\n",
      "\t Genero da 1000 a 1010\n",
      "\t Genero da 1010 a 1020\n",
      "\t Genero da 1020 a 1030\n",
      "\t Genero da 1030 a 1040\n",
      "\t Genero da 1040 a 1050\n",
      "\t Genero da 1050 a 1060\n",
      "\t Genero da 1060 a 1070\n",
      "\t Genero da 1070 a 1080\n",
      "\t Genero da 1080 a 1090\n",
      "\t Genero da 1090 a 1100\n",
      "\t Genero da 1100 a 1110\n",
      "\t Genero da 1110 a 1120\n",
      "\t Genero da 1120 a 1130\n",
      "\t Genero da 1130 a 1140\n",
      "\t Genero da 1140 a 1150\n",
      "\t Genero da 1150 a 1160\n",
      "\t Genero da 1160 a 1170\n",
      "\t Genero da 1170 a 1180\n",
      "\t Genero da 1180 a 1190\n",
      "\t Genero da 1190 a 1200\n",
      "\t Genero da 1200 a 1210\n",
      "\t Genero da 1210 a 1220\n",
      "\t Genero da 1220 a 1230\n",
      "\t Genero da 1230 a 1240\n",
      "\t Genero da 1240 a 1250\n",
      "\t Genero da 1250 a 1260\n",
      "\t Genero da 1260 a 1270\n",
      "\t Genero da 1270 a 1280\n",
      "\t Genero da 1280 a 1290\n",
      "\t Genero da 1290 a 1300\n",
      "\t Genero da 1300 a 1310\n",
      "\t Genero da 1310 a 1320\n",
      "\t Genero da 1320 a 1330\n",
      "\t Genero da 1330 a 1340\n",
      "\t Genero da 1340 a 1350\n",
      "\t Genero da 1350 a 1360\n",
      "\t Genero da 1360 a 1370\n",
      "\t Genero da 1370 a 1380\n",
      "\t Genero da 1380 a 1390\n",
      "\t Genero da 1390 a 1400\n",
      "\t Genero da 1400 a 1410\n",
      "\t Genero da 1410 a 1420\n",
      "\t Genero da 1420 a 1430\n",
      "\t Genero da 1430 a 1440\n",
      "\t Genero da 1440 a 1450\n",
      "\t Genero da 1450 a 1460\n",
      "\t Genero da 1460 a 1470\n",
      "\t Genero da 1470 a 1480\n",
      "\t Genero da 1480 a 1490\n",
      "\t Genero da 1490 a 1500\n",
      "\t Genero da 1500 a 1510\n",
      "\t Genero da 1510 a 1520\n",
      "\t Genero da 1520 a 1530\n",
      "\t Genero da 1530 a 1540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 17/33 [19:41<18:31, 69.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page-blocks-1-3_vs_4.csv\n",
      "\n",
      "üìÇ Analizzando dataset: page-blocks-1-3_vs_4.csv\n",
      "  üîπ Classe maggioritaria: 0 (443)\n",
      "  üîπ Classe minoritaria: 1 (28)\n",
      "  ‚ûï Generer√≤ 415 nuove tuple per bilanciare la classe minoritaria.\n",
      "\t Genero da 0 a 10\n",
      "\t Genero da 10 a 20\n",
      "\t Genero da 20 a 30\n",
      "\t Genero da 30 a 40\n",
      "\t Genero da 40 a 50\n",
      "\t Genero da 50 a 60\n",
      "\t Genero da 60 a 70\n",
      "\t Genero da 70 a 80\n",
      "\t Genero da 80 a 90\n",
      "\t Genero da 90 a 100\n",
      "\t Genero da 100 a 110\n",
      "\t Genero da 110 a 120\n",
      "\t Genero da 120 a 130\n",
      "\t Genero da 130 a 140\n",
      "\t Genero da 140 a 150\n",
      "\t Genero da 150 a 160\n",
      "\t Genero da 160 a 170\n",
      "\t Genero da 170 a 180\n",
      "\t Genero da 180 a 190\n",
      "\t Genero da 190 a 200\n",
      "\t Genero da 200 a 210\n",
      "\t Genero da 210 a 220\n",
      "\t Genero da 220 a 230\n",
      "\t Genero da 230 a 240\n",
      "\t Genero da 240 a 250\n",
      "\t Genero da 250 a 260\n",
      "\t Genero da 260 a 270\n",
      "\t Genero da 270 a 280\n",
      "\t Genero da 280 a 290\n",
      "\t Genero da 290 a 300\n",
      "\t Genero da 300 a 310\n",
      "\t Genero da 310 a 320\n",
      "\t Genero da 320 a 330\n",
      "\t Genero da 330 a 340\n",
      "\t Genero da 340 a 350\n",
      "\t Genero da 350 a 360\n",
      "\t Genero da 360 a 370\n",
      "\t Genero da 370 a 380\n",
      "\t Genero da 380 a 390\n",
      "\t Genero da 390 a 400\n",
      "\t Genero da 400 a 410\n",
      "\t Genero da 410 a 420\n",
      "\t Genero da 420 a 430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 18/33 [23:01<19:54, 79.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obesity_onevsrest_3.csv\n",
      "\n",
      "üìÇ Analizzando dataset: Obesity_onevsrest_3.csv\n",
      "  üîπ Classe maggioritaria: 0 (1797)\n",
      "  üîπ Classe minoritaria: 1 (290)\n",
      "  ‚ûï Generer√≤ 1507 nuove tuple per bilanciare la classe minoritaria.\n",
      "\t Genero da 0 a 10\n",
      "\t Genero da 10 a 20\n",
      "\t Genero da 20 a 30\n",
      "\t Genero da 30 a 40\n",
      "\t Genero da 40 a 50\n",
      "\t Genero da 50 a 60\n",
      "\t Genero da 60 a 70\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "csv_files = [f for f in os.listdir(\".\") if f.endswith(\".csv\")]\n",
    "if not csv_files:\n",
    "    print(\"‚ö†Ô∏è Nessun file CSV trovato nella directory corrente.\")\n",
    "\n",
    "csv_files_already_processed = [f.split(\"_llama\")[0] for f in os.listdir(\"LLM\") if f.endswith(\".txt\")]\n",
    "files_already_processed = set(csv_files_already_processed)\n",
    "\n",
    "for file in tqdm(csv_files,total=len(csv_files)):\n",
    "    print(file)\n",
    "    if file.replace(\".csv\",\"\") not in files_already_processed:\n",
    "        augment_dataset(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "031dc477-05f6-4ad9-9232-2f675ea1470b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obesity_onevsrest_1.csv\n",
      "page-blocks-1-3_vs_4.csv\n",
      "Obesity_onevsrest_3.csv\n",
      "Obesity_onevsrest_2.csv\n",
      "Obesity_onevsrest_6.csv\n",
      "pima.csv\n",
      "Obesity_onevsrest_5.csv\n",
      "abalone9-18.csv\n",
      "Obesity_onevsrest_4.csv\n",
      "yeast1.csv\n",
      "dermatology-6.csv\n",
      "yeast3.csv\n",
      "vehicle2.csv\n",
      "vehicle3.csv\n",
      "vehicle1.csv\n",
      "vehicle0.csv\n",
      "vowel0.csv\n"
     ]
    }
   ],
   "source": [
    "csv_files_already_processed = [f.split(\"_llama\")[0] for f in os.listdir(\"LLM\") if f.endswith(\".txt\")]\n",
    "files_already_processed = set(csv_files_already_processed)\n",
    "for file in csv_files:\n",
    "    if file.replace(\".csv\",\"\") not in files_already_processed:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "317a42cb-4cfe-4f85-adf2-8afe35963f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama(prompt: str, model: str = MODEL_NAME) -> str:\n",
    "    \"\"\"\n",
    "    Interroga Ollama in locale e restituisce la risposta testuale.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", model],\n",
    "            input=prompt.encode(\"utf-8\"),\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            check=True\n",
    "        )\n",
    "        return result.stdout.decode(\"utf-8\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"‚ùå Errore nell'interrogazione di Ollama:\", e.stderr.decode(\"utf-8\"))\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcfe6e9a-05fc-4a5a-8ef6-6d251c7b089a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao Stefano! Sono felice di conoscerti. Come posso aiutarti oggi?\\n\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = call_ollama(\"Ciao sono stefano\")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
